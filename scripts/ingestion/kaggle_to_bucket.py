# ------------------------------------------------------------------
# IMPORTS
# ------------------------------------------------------------------
import sys
import os
import subprocess
from pathlib import Path
from datetime import datetime, timezone

import pandas as pd
from dotenv import load_dotenv

# ------------------------------------------------------------------
# PATH SETUP
# ------------------------------------------------------------------
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.append(str(PROJECT_ROOT))

from config.data_connections import get_s3_client
from scripts.utils.lake_retetions import cleanup_old_runs

# ------------------------------------------------------------------
# CONFIG
# ------------------------------------------------------------------
load_dotenv(override=True)

os.environ["KAGGLE_CONFIG_DIR"] = str(
    (PROJECT_ROOT / "config").resolve()
)

DATASET = "olistbr/brazilian-ecommerce"
BUCKET_NAME = "kaggle"

# ------------------------------------------------------------------
# DATASETS SELECIONADOS
# ------------------------------------------------------------------
ALLOWED_DATASETS = {
    "olist_products_dataset",
    "olist_order_items_dataset",
    "olist_orders_dataset",
    "olist_customers_dataset",
    "olist_geolocation_dataset",
}

# ------------------------------------------------------------------
# VERSIONAMENTO
# ------------------------------------------------------------------
RUN_ID = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")

LANDING_BASE_PATH = "olist/landing/"
LANDING_PATH = f"{LANDING_BASE_PATH}run_id={RUN_ID}/"

MAX_LANDING_RUNS = int(os.getenv("LANDING_MAX_RUNS", 3))

# ------------------------------------------------------------------
# LOCAL PATHS
# ------------------------------------------------------------------
CSV_DIR = PROJECT_ROOT / "data/landing/csv"
PARQUET_DIR = PROJECT_ROOT / "data/landing/parquet"

CSV_DIR.mkdir(parents=True, exist_ok=True)
PARQUET_DIR.mkdir(parents=True, exist_ok=True)

# ------------------------------------------------------------------
# KAGGLE DOWNLOAD
# ------------------------------------------------------------------
def download_kaggle_dataset():
    print(f"üîç Verificando config em: {os.environ['KAGGLE_CONFIG_DIR']}")
    
    token_path = Path(os.environ["KAGGLE_CONFIG_DIR"]) / "kaggle.json"
    if not token_path.exists():
        print(f"‚ùå ERRO: Arquivo {token_path} n√£o encontrado!")
        return

    print(f"üì• Baixando dataset para: {CSV_DIR}")
    CSV_DIR.mkdir(parents=True, exist_ok=True)

    try:
        command = f"kaggle datasets download -d {DATASET} -p {str(CSV_DIR)} --unzip"
        result = subprocess.run(
            command,
            shell=True, 
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            print(f"‚ùå Erro do Kaggle CLI:\n{result.stderr}")
            print(f"üí° Dica: Verifique se voc√™ aceitou os termos do dataset no site do Kaggle.")
        else:
            print(f"‚úÖ Download conclu√≠do!")
            files = list(CSV_DIR.glob("*"))
            print(f"üìÇ Arquivos na pasta: {[f.name for f in files]}")
            
    except Exception as e:
        print(f"‚ùå Erro ao executar comando: {e}")


# ------------------------------------------------------------------
# LIMPEZA DE DIRET√ìRIO PARQUET
# ------------------------------------------------------------------
def clean_parquet_dir():
    print("üßπ Limpando diret√≥rio de Parquet...")

    for file in PARQUET_DIR.glob("*.parquet"):
        file.unlink()


# ------------------------------------------------------------------
# CSV ‚Üí Parquet (somente selecionados)
# ------------------------------------------------------------------
def csv_to_parquet():
    print("üîÑ Convertendo CSV para Parquet...")
    csv_files = list(CSV_DIR.glob("*.csv"))
    
    if not csv_files:
        print("‚ö†Ô∏è Nenhum arquivo CSV encontrado em CSV_DIR!")
        return

    for csv_file in csv_files:
        dataset_name = csv_file.stem

        if dataset_name not in ALLOWED_DATASETS:
            print(f"  - Ignorado: {csv_file.name}")
            continue

        parquet_file = PARQUET_DIR / f"{dataset_name}.parquet"

        print(f"  - {csv_file.name} ‚Üí {parquet_file.name}")

        df = pd.read_csv(csv_file)

        df.to_parquet(
            parquet_file,
            engine="pyarrow",
            index=False,
        )

    print("‚úÖ Convers√£o conclu√≠da")


# ------------------------------------------------------------------
# UPLOAD LANDING (somente selecionados)
# ------------------------------------------------------------------
def upload_to_minio():
    print("‚òÅÔ∏è Enviando Parquets permitidos para o MinIO (Landing)...")

    s3 = get_s3_client()

    for parquet_file in PARQUET_DIR.glob("*.parquet"):
        dataset_name = parquet_file.stem

        if dataset_name not in ALLOWED_DATASETS:
            print(f"  - Ignorado no upload: {parquet_file.name}")
            continue

        object_key = f"{LANDING_PATH}{parquet_file.name}"

        print(f"  - s3://{BUCKET_NAME}/{object_key}")

        s3.upload_file(
            Filename=str(parquet_file),
            Bucket=BUCKET_NAME,
            Key=object_key,
        )

    print("‚úÖ Upload conclu√≠do")


# ------------------------------------------------------------------
# PIPELINE
# ------------------------------------------------------------------
def run():
    print("üöÄ Iniciando Landing: Olist (Kaggle)")
    print(f"üßæ run_id = {RUN_ID}")
    print(f"üßπ Pol√≠tica de reten√ß√£o: manter {MAX_LANDING_RUNS} runs")

    download_kaggle_dataset()

    csv_to_parquet()
    upload_to_minio()
    clean_parquet_dir()

    print("üßπ Aplicando pol√≠tica de reten√ß√£o...")
    cleanup_old_runs(
        bucket=BUCKET_NAME,
        base_path=LANDING_BASE_PATH,
        max_runs=MAX_LANDING_RUNS,
        protect_run_id=RUN_ID,
    )

    print("üèÅ Landing Olist finalizada com sucesso!")


# ------------------------------------------------------------------
# ENTRYPOINT
# ------------------------------------------------------------------
if __name__ == "__main__":
    run()