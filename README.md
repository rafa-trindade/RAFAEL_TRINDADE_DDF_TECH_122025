# RAFAEL TRINDADE - DDF_TECH_122025

## üìå Introdu√ß√£o
Este reposit√≥rio cont√©m a resolu√ß√£o do Case T√©cnico para a posi√ß√£o Engenheiro de Dados J√∫nior na **Dadosfera**. O projeto foca em uma empresa de E-commerce, utilizando o dataset brasileiro da Olist (Kaggle) para construir uma plataforma de dados ponta a ponta, integrando engenharia moderna, modelagem dimensional e visualia√ß√£o de dados.

---

## üõ†Ô∏è Arquitetura Geral da Solu√ß√£o
A arquitetura proposta segue padr√µes modernos de **Lakehouse** + **Data Warehouse Anal√≠tico**, combinando **MinIO**, **DuckDB**, **PostgreSQL**, **dbt**, **Pandera** e **Dadosfera**.

### üìå Arquitetura Proposta:

![Arquitetura](docs/data_architecture/arquitetura_proposta.png)

### Principais componentes:

- **Fonte de Dados:** Kaggle - Olist (CSV)
- **Data Lake:** MinIO camada Landing (extra: Bronze, Silver, Gold) 
- **Engine de Processamento:** DuckDB
- **Data Warehouse:** PostgreSQL (Docker)
- **Transforma√ß√µes:** dbt
- **Qualidade de Dados:** Pandera + dbt tests
- **Analytics & BI:** Dadosfera + Metabase
- **Data Apps:** Streamlit

---

## üìö Mapeamento da Documenta√ß√£o

### üèóÔ∏è Data Architecture
üìÅ `docs/data_architecture/`

Descreve a arquitetura t√©cnica do projeto em execu√ß√£o:
- Componentes da stack (MinIO, PostgreSQL, DuckDB, Pandera, Docker)
- Pap√©is e responsabilidades de cada servi√ßo
- Integra√ß√£o entre ingest√£o, processamento e armazenamento

---

### üèõÔ∏è Data Governance
üìÅ `docs/data_governance/`

Centraliza as pol√≠ticas e diretrizes do projeto e mapeia como a solu√ß√£o atende,
na pr√°tica, aos pilares de **Data Governance**.
- Pol√≠tica de reten√ß√£o baseada em execu√ß√µes t√©cnicas (`run_id`)
- Defini√ß√£o de contratos gerais de qualidade de dados
- Estrat√©gias seguras de reprocessamento e rollback
- Suporte nativo √† auditoria, observabilidade e controle de custos
- Governan√ßa aplicada via c√≥digo e automa√ß√£o

---

### üß¨ Data Lineage
üìÅ `docs/data_lineage/`

Documenta a rastreabilidade ponta a ponta dos dados:
- Origem dos dados
- Transforma√ß√µes por camada (Landing ‚Üí Raw ‚Üí Staging ‚Üí Core ‚Üí Marts ‚Üí Dadosfera)

---

### üß± Data Modeling
üìÅ `docs/data_modeling/`

- Documenta as decis√µes de modelagem de dados adotadas no projeto:
- Modelagem OLTP dos dados de origem
- Modelagem OLAP orientada a analytics
- Diagramas e imagens das estruturas de dados

---

### üîç Data Observability
üìÅ `docs/data_observability/`

Mapeia como o projeto atende aos pilares de Data Observability:
- Freshness
- Volume
- Schema
- Distribution
- Lineage
- Quality
- Reliability e Reprocessamento

A observabilidade emerge como resultado das decis√µes de arquitetura e governan√ßa.

---

### üìä Data Profiling
üìÅ `docs/data_profiling/`

Apresenta an√°lises explorat√≥rias e estat√≠sticas dos dados:
- Volume por camada
- Cardinalidade
- Distribui√ß√£o de valores
- Percentual de nulos

Utilizado como base para qualidade e observabilidade.

---

### ‚öôÔ∏è Configura√ß√µes de Infraestrutura
üìÅ `docs/configuracoes/`

- Centraliza guias t√©cnicos de configura√ß√£o do ambiente de infraestrutura e servi√ßos
utilizados no projeto:
- Configura√ß√£o do PostgreSQL em Docker com SSL/TLS habilitado
- Cria√ß√£o, permiss√µes e montagem segura de certificados SSL
- Suporte a acesso seguro por ferramentas externas (ex: Dadosfera)

---

# üìë Itens do Case

## Item 0 - Agilidade e Planejamento

### Metodologia

O planejamento do projeto foi realizado seguindo boas pr√°ticas do PMBOK, combinado com metodologias √°geis.

**Gest√£o:** Quadro Kanban para controle de tarefas, entregas t√©cnicas e milestones do projeto.

![Quadro GitHub Projects](docs/images/project.png)


## Item 1 - Base de Dados
**Dataset:** Brazilian E-Commerce Dataset by Olist (Kaggle).

**Justificativa:** 
- Dataset real, amplamente utilizado em projetos anal√≠ticos
- Dom√≠nio aderente ao cen√°rio de e-commerce
- Volume superior a 100.000 registros
- Cont√©m dados transacionais e descritivos

**Principais tabelas:**
- `olist_orders_dataset`
- `olist_order_items_dataset`
- `olist_products_dataset`
- `olist_customers_dataset`
- `olist_geolocation_dataset`


## Item 2 e 3 - Integrar e Explorar (Dadosfera)

### Estrat√©gia de Ingest√£o

A ingest√£o foi dividida em etapas claras:

**Extra√ß√£o Kaggle ‚Üí MinIO (Landing)**

- Scripts em Python
- Versionamento por `run_id`
- Dados armazenados em formato parquet
- Verifica√ß√£o de Qualidade com Pandera

**Carga Anal√≠tica no Data Warehouse**

- PostgreSQL utilizado como Data Warehouse anal√≠tico
- Transforma√ß√µes realizadas com dbt
- Constru√ß√£o do Star Schema (Kimball) diretamente no DW
- Aplica√ß√£o de testes de qualidade (dbt tests)
- Microtransforma√ß√µes simuladas no contexto anal√≠tico
- Motor de processamento na camada de ingest√£o: DuckDB

**Lakehouse: Landing ‚Üí Bronze / Silver / Gold (Arquitetura B√¥nus)**

- Organiza√ß√£o incremental
- Padroniza√ß√£o de schemas
- Prepara√ß√£o para consumo por modelos de ML

**Carga e cataloga√ß√£o dos dados utilizando o m√≥dulo de Coleta da Dadosfera.**

- M√≥dulo de Coleta da Dadosfera
- Execu√ß√£o a partir de VPS dedicada
- PostgreSQL em container com SSL habilitado

A **carga** foi realizada a partir de uma VPS dedicada, configurada para permitir integra√ß√£o segura com a plataforma.

A **cataloga√ß√£o dos dados** foi realizada diretamente na plataforma Dadosfera, onde os ativos ingeridos foram registrados, descritos e organizados, possibilitando sua explora√ß√£o, governan√ßa e reutiliza√ß√£o.

**Ativo na Dadosfera:** [[PIPELINE](https://app.dadosfera.ai/pt-BR/collect/pipelines/fb3dc75a-11f8-4c61-99c4-e804871d166d)]  [[LINK PARA O DATASET CATALOGADO](https://app.dadosfera.ai/pt-BR/catalog/data-assets?pipeline_id=fb3dc75a-11f8-4c61-99c4-e804871d166d&pipeline_name=RAFAEL%20TRINDADE%20-%20DDF_TECH_122025)]


## Item 4 - Data Quality

### Abordagem

A qualidade dos dados foi tratada desde o in√≠cio do pipeline.

### Ferramentas Utilizadas

- **Pandera (Python)** - valida√ß√£o de schemas
- **dbt tests** - testes anal√≠ticos

### Entreg√°vel

Gera√ß√£o de relat√≥rio de qualidade para identifica√ß√£o de nulos e tipos incorretos.

**Resultado:** [[PANDERA REPORTS](https://github.com/rafa-trindade/RAFAEL_TRINDADE_DDF_TECH_122025/tree/main/reports/pandera)]  [[DBT REPORTS](https://github.com/rafa-trindade/RAFAEL_TRINDADE_DDF_TECH_122025/tree/main/reports/dbt)]


## Item 6 - Modelagem de Dados

Modelagem dimensional seguindo os princ√≠pios de Ralph Kimball.

**Esquema:** Star Schema (Tabelas Fato e Dimens√£o).<br>
**Justificativa:** Otimiza√ß√£o para consultas anal√≠ticas e performance no BI.

### Estrutura Final

**Fato:**

- `fact_order_items`

**Dimens√µes:**

- `dim_customers`
- `dim_products`
- `dim_geolocation`
- `dim_date` *(dbt_seed)*
- `dim_time` *(dbt_seed)*

### `modelo_olap`

![Modelagem](docs/data_modeling/olap.png)

### origem: `modelo_oltp`

![oltp](docs/data_modeling/oltp.png)

---

## Item 7 - Analisar (Visualiza√ß√£o)
Dashboard interativo constru√≠do na Dadosfera (Metabase).
* **An√°lises:** 
* **Query SQL:** [LINK PARA O ARQUIVO SQL DE CONSULTA]

---

## Item 8 - Pipelines

Pipeline de processamento automatizado utilizando os Steps da Dadosfera.

**Status:** [[PIPELINE](https://app.dadosfera.ai/pt-BR/collect/pipelines/fb3dc75a-11f8-4c61-99c4-e804871d166d)]

---

## Item 9 - Data App (Streamlit)
Desenvolvimento de um Data App utilizando o Streamlit.
* **URL do App:** [[STREAMLIT VPS](http://54.39.98.107:8501/)]


---

## Item 10 - Apresenta√ß√£o (Pitch T√©cnico)
Apresenta√ß√£o da solu√ß√£o e demonstra√ß√£o da viabilidade de substitui√ß√£o da arquitetura atual pela Dadosfera.

üëâ **[LINK PARA O V√çDEO NO YOUTUBE - N√ÉO LISTADO]**

---

**Portf√≥lio:** [https://rafa-trindade.github.io/](https://rafa-trindade.github.io/)<br>
**LinkedIn:** [https://www.linkedin.com/in/rafatrindade/](https://www.linkedin.com/in/rafatrindade/)