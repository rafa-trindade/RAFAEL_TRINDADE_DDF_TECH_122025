# RAFAEL TRINDADE - DDF_TECH_122025


> **Portf√≥lio:** [https://rafa-trindade.github.io/](https://rafa-trindade.github.io/)<br>
> **LinkedIn:** [https://www.linkedin.com/in/rafatrindade/](https://www.linkedin.com/in/rafatrindade/)


## üìå Introdu√ß√£o e Vis√£o Geral

Este reposit√≥rio apresenta a resolu√ß√£o do **Case T√©cnico para a posi√ß√£o de Engenheiro de Dados J√∫nior na Dadosfera**.

O projeto tem como contexto uma empresa de **E-commerce** e utiliza o **dataset brasileiro da Olist (Kaggle)** como base para a constru√ß√£o de uma **plataforma de dados ponta a ponta**, desenvolvida no formato de **Prova de Conceito (PoC)**.

Ap√≥s validar a viabilidade t√©cnica da arquitetura proposta, o projeto evidencia seus **desafios operacionais**, criando o contexto para demonstrar como a plataforma **Dadosfera** se posiciona como o pr√≥ximo passo natural dessa Prova de Conceito, **consolidando toda a esteira anal√≠tica em uma solu√ß√£o √∫nica, escal√°vel e sustent√°vel**, orientada √† **gera√ß√£o cont√≠nua de valor para o neg√≥cio**.


## üõ†Ô∏è Arquitetura Geral da Solu√ß√£o - *Prova de Conceito (PoC)*
A arquitetura proposta segue padr√µes modernos de **Lakehouse** + **Data Warehouse Anal√≠tico**, combinando **MinIO**, **DuckDB**, **PostgreSQL**, **dbt**, **Pandera** e **Dadosfera**.

### Principais componentes:

- **Fonte de Dados:** Kaggle - Olist (CSV)
- **Data Lake:** MinIO - *Camada Landing* (com organiza√ß√£o em Bronze, Silver e Gold)
- **Engine de Processamento:** DuckDB
- **Data Warehouse:** PostgreSQL (containerizado via Docker)
- **Transforma√ß√µes:** dbt
- **Qualidade de Dados:** Pandera + dbt tests
- **Visualiza√ß√µes e Cat√°logo de Dados:** Dadosfera + Metabase
- **Data App Anal√≠tico:** Streamlit

![Arquitetura](docs/images/arquitetura_proposta.png)


## üìö Mapeamento da Documenta√ß√£o

### üèóÔ∏è Data Architecture
üìÑ [`docs/data_architecture/`](docs/data_architecture/README.md)

Descreve a arquitetura t√©cnica da **Prova de Conceito (PoC)** em execu√ß√£o:
- Vis√£o geral da arquitetura **Lakehouse + Data Warehouse Anal√≠tico**
- Componentes da stack (Kaggle API, Python, MinIO, DuckDB, PostgreSQL, dbt, Pandera, Docker)
- Pap√©is e responsabilidades de cada servi√ßo
- Integra√ß√£o entre ingest√£o, carga, modelagem anal√≠tica e consumo
- Execu√ß√£o do ambiente em **VPS**, priorizando simplicidade e portabilidade

---

### üìò Data Catalog
üìÅ [`docs/data_catalog/*`](docs/data_catalog/)

Centraliza a **documenta√ß√£o sem√¢ntica dos modelos anal√≠ticos (Data Marts)**, descrevendo de forma clara e padronizada:
- Objetivo e contexto de cada tabela anal√≠tica
- Granularidade e chaves l√≥gicas
- Significado dos campos e m√©tricas
- Regras de neg√≥cio aplicadas
- Principais casos de uso anal√≠ticos

Funciona como a **camada de tradu√ß√£o entre engenharia e consumo de dados**, facilitando o entendimento por analistas, times de neg√≥cio e stakeholders.

> **Observa√ß√£o:** Para esta **Prova de Conceito (PoC)**, o cat√°logo foi **gerado automaticamente com apoio de um LLM**, a partir da leitura e interpreta√ß√£o dos modelos SQL dos Data Marts, resultando em documenta√ß√£o versionada e padronizada.

---

### üèõÔ∏è Data Governance
üìÑ [`docs/data_governance/`](docs/data_governance/README.md)

Centraliza as pol√≠ticas e diretrizes do projeto e mapeia como a solu√ß√£o atende,
na pr√°tica, aos pilares de **Data Governance**:
- Pol√≠tica de reten√ß√£o baseada em execu√ß√µes t√©cnicas (`run_id`)
- Defini√ß√£o de contratos gerais de dados
- Estrat√©gias seguras de reprocessamento e rollback
- Governan√ßa aplicada via c√≥digo e automa√ß√£o
- Suporte nativo √† auditoria, observabilidade e controle operacional

---

### üß¨ Data Lineage
üìÑ [`docs/data_lineage/`](docs/data_lineage/README.md)

Documenta a rastreabilidade ponta a ponta dos dados:
- Origem dos dados (Kaggle ‚Üí Data Lake)
- Fluxo t√©cnico entre camadas:
  - Landing (MinIO)
  - Data Warehouse: Raw ‚Üí Staging ‚Üí Core ‚Üí Marts
- Separa√ß√£o expl√≠cita entre transforma√ß√µes t√©cnicas e sem√¢nticas
- Base para auditoria, impacto de mudan√ßas e governan√ßa anal√≠tica

---

### üîç Data Observability
üìÑ [`docs/data_observability/`](docs/data_observability/README.md)

Mapeia como o projeto atende aos pilares cl√°ssicos de **Data Observability**:
- Freshness
- Volume
- Schema
- Distribution
- Lineage
- Quality
- Reliability e Reprocessamento

A observabilidade emerge como **resultado natural das decis√µes de arquitetura,
governan√ßa e qualidade de dados**, sem depend√™ncia de ferramentas externas.

---

### üìä Data Profiling
üìÅ [`docs/data_profiling/landing/*`](docs/data_profiling/landing/)

Apresenta an√°lises explorat√≥rias e estat√≠sticas dos dados na camada **Landing**,
com **um relat√≥rio de profiling por dataset**:
- Volumetria
- Cardinalidade
- Distribui√ß√£o de valores
- Percentual de nulos

Utilizado como base para **Data Quality**, **Data Observability** e defini√ß√£o de contratos de dados.

> **Observa√ß√£o:** O profiling foi gerado por meio de um **script utilit√°rio de EDA h√≠brido (Python + Jupyter Notebook)**, combinando automa√ß√£o e an√°lise explorat√≥ria assistida, com gera√ß√£o de relat√≥rios versionados para suporte √†s decis√µes de qualidade e modelagem.

---

### ‚úÖ Data Quality
üìÑ [`docs/data_quality/`](docs/data_quality/README.md)

Descreve como a **qualidade de dados** √© garantida ao longo de todo o pipeline:
- Valida√ß√£o de **schema e estrutura antes da persist√™ncia na camada Landing** com **Pandera**
- Contratos de dados expl√≠citos por dataset
- Logs t√©cnicos audit√°veis por execu√ß√£o (`run_id`)
- Testes de integridade, unicidade e regras de neg√≥cio com **dbt tests**
- Separa√ß√£o clara entre:
  - Qualidade t√©cnica (ingest√£o)
  - Qualidade sem√¢ntica e anal√≠tica (Data Warehouse)

---

### üß± Infraestrutura e Execu√ß√£o
üìÅ [`docs/infrastructure/*`](docs/infrastructure)

Documenta as configura√ß√µes t√©cnicas e operacionais do ambiente de execu√ß√£o,
distribu√≠das em m√∫ltiplos guias t√©cnicos:
- PostgreSQL com SSL/TLS em VPS (Docker)
- Execu√ß√£o, depend√™ncias e orquestra√ß√£o do dbt (staging, core e marts)

---

### üé§ Apresenta√ß√£o - Pitch T√©cnico
üìÑ [`docs/presentation/`](docs/presentation/README.md)

Documenta a **apresenta√ß√£o executiva e t√©cnica do case**, conectando os resultados da **Prova de Conceito (PoC)** √† evolu√ß√£o natural da solu√ß√£o na plataforma **Dadosfera**:
- S√≠ntese do que foi validado tecnicamente na PoC
- Limita√ß√µes operacionais de uma arquitetura manual
- Dadosfera como plataforma de **centraliza√ß√£o, governan√ßa e escala**
- Evolu√ß√£o do pipeline para um cen√°rio produtivo e sustent√°vel
- Vis√£o de pr√≥ximos passos anal√≠ticos e estrat√©gicos

---

# üìë Itens do Case

# Item 0 - Agilidade e Planejamento

### Metodologia:

O planejamento do projeto foi estruturado com base nas boas pr√°ticas do **PMBOK**, garantindo governan√ßa, controle de escopo, riscos e custos, combinado com **metodologias √°geis**, priorizando entregas incrementais, adapta√ß√£o cont√≠nua e gera√ß√£o r√°pida de valor ao neg√≥cio.

Essa abordagem h√≠brida permitiu alinhar controle executivo e flexibilidade t√©cnica ao longo de todo o ciclo de vida do projeto.

---

### Gest√£o do Projeto:

A gest√£o das atividades foi realizada por meio de um **Quadro Kanban**, utilizado para organizar o fluxo de trabalho desde a concep√ß√£o at√© a implementa√ß√£o final.

O Kanban possibilitou:
- Controle visual das tarefas planejadas e em execu√ß√£o  
- Acompanhamento das **entregas t√©cnicas**  
- Defini√ß√£o e monitoramento de **milestones do projeto**  
- Identifica√ß√£o de depend√™ncias e pontos cr√≠ticos  

O quadro foi implementado utilizando o **GitHub Projects**, integrando planejamento, execu√ß√£o e versionamento do c√≥digo em um √∫nico ambiente.

#### üîó **[[GITHUB PROJECT](https://github.com/users/rafa-trindade/projects/2)]**

![Quadro GitHub Projects](docs/images/project.png)

### üìä Matriz Formal de Riscos e Custos (PMBOK)

Esta se√ß√£o apresenta a an√°lise de riscos, estimativa de custos e aloca√ß√£o de recursos do projeto, seguindo as boas pr√°ticas do PMBOK, aplicadas a um contexto √°gil e incremental.

---

### 1Ô∏è‚É£ Matriz de Riscos do Projeto:

**Escala adotada:**
- **Probabilidade (P):** Baixa (1) | M√©dia (2) | Alta (3)  
- **Impacto (I):** Baixo (1) | M√©dio (2) | Alto (3)  
- **N√≠vel de Risco:** P √ó I  

| ID | Risco | Fase Impactada | P | I | N√≠vel | Estrat√©gia de Mitiga√ß√£o |
|----|------|----------------|---|---|--------|--------------------------|
| R1 | Instabilidade ou indisponibilidade da fonte de dados | Integra√ß√£o | 2 | 3 | 6 (Alto) | Pol√≠tica de reten√ß√£o e versionamento dos datasets e valida√ß√£o pr√©-ingest√£o |
| R2 | Volume de dados superior √† capacidade de mem√≥ria | Processamento | 2 | 3 | 6 (Alto) | Uso de DuckDB com processamento columnar e leitura por chunks |
| R3 | Dados inconsistentes ou ausentes | Qualidade | 3 | 2 | 6 (Alto) | Valida√ß√µes automatizadas com Pandera e regras de schema |
| R4 | Falha no deploy do Data App | Data Apps | 1 | 3 | 3 (M√©dio) | Logging e execu√ß√£o controlada na VPS |
| R5 | Mudan√ßa de escopo durante o desenvolvimento | Planejamento | 1 | 2 | 2 (Baixo) | Arquitetura modular e versionamento via Git |
| R6 | Depend√™ncia excessiva de ferramentas espec√≠ficas | Arquitetura | 1 | 2 | 2 (Baixo) | Uso de padr√µes abertos e stack desacoplada |

> A gest√£o de riscos foi realizada de forma preventiva, com identifica√ß√£o, an√°lise qualitativa e defini√ß√£o de estrat√©gias de mitiga√ß√£o.

---

### 2Ô∏è‚É£ Estimativa de Custos do Projeto:

#### Premissas
- Projeto no formato **Prova de Conceito (PoC)**
- Execu√ß√£o em ambiente cloud leve
- Uso predominante de ferramentas open source
- Desenvolvimento realizado por um √∫nico Engenheiro de Dados

---

#### üí∞ Custos de Infraestrutura

| Recurso | Tipo | Custo Mensal Estimado |
|------|------|------------------------|
| VPS (6 vCPU / 12GB RAM / 100 GB) | Cloud | R$ 80 |
| **Total Infraestrutura** |  | **R$ 80 / m√™s** |

---

#### üë®‚Äçüíª Custos de Recursos Humanos

| Papel | Aloca√ß√£o | Horas Estimadas | Custo Estimado |
|----|----------|-----------------|----------------|
| Engenheiro de Dados | 100% | 120h | R$ 8.000 |

---

#### üß∞ Custos de Ferramentas

| Ferramenta | Tipo | Custo |
|----------|------|-------|
| PostgreSQL | Open Source | R$ 0 |
| DuckDB | Open Source | R$ 0 |
| dbt Core | Open Source | R$ 0 |
| Pandera | Open Source | R$ 0 |
| Streamlit | Open Source | R$ 0 |
| Dadosfera | Ambiente de Avalia√ß√£o | R$ 0 |

---

#### üíµ Custo Total Estimado

| Categoria | Valor |
|----------|-------|
| Infraestrutura (1 m√™s) | R$ 80 |
| Recursos Humanos | R$ 8.000 |
| **Total Geral** | **R$ 8.080** |

---

### 3Ô∏è‚É£ Justificativa da Decis√£o Arquitetural:

Para o porte do projeto, volume de dados e objetivo de entrega r√°pida de valor, o **DuckDB** foi escolhido por oferecer:

- Alta performance anal√≠tica em ambientes *single-node*
- Baixo custo operacional
- Simplicidade de setup e manuten√ß√£o
- Integra√ß√£o nativa com Python e dbt

Ferramentas distribu√≠das como **Spark ou Snowpark** n√£o foram adotadas por aumentarem a complexidade e o custo operacional sem ganhos proporcionais para este cen√°rio, uma vez que o volume de dados e o padr√£o de acesso n√£o justificam processamento distribu√≠do.

---

No contexto de **Qualidade de Dados**, a biblioteca **Pandera** foi adotada em substitui√ß√£o a ferramentas como **Great Expectations** ou **Soda**, pelos seguintes motivos:

- Defini√ß√£o de regras de qualidade diretamente em c√≥digo Python, facilitando versionamento e manuten√ß√£o
- Integra√ß√£o natural com pipelines existentes e ambientes de processamento leve
- Menor overhead operacional para um projeto no formato *Prova de Conceito (PoC)*

A escolha do Pandera permitiu implementar valida√ß√µes robustas e reproduz√≠veis, mantendo a solu√ß√£o simples, eficiente e alinhada ao objetivo de entrega r√°pida de valor, sem comprometer a governan√ßa da qualidade dos dados.

---

### 4Ô∏è‚É£ Aloca√ß√£o de Recursos por Fase:

| Fase do Projeto | Percentual de Esfor√ßo |
|-----------------|-----------------------|
| Planejamento e Arquitetura | 15% |
| Integra√ß√£o de Dados | 20% |
| Modelagem e Transforma√ß√µes | 25% |
| Qualidade de Dados | 15% |
| An√°lises e Visualiza√ß√£o | 15% |
| Data App e Deploy | 10% |

---

### 5Ô∏è‚É£ Conclus√£o:

O projeto foi planejado e executado com base nas boas pr√°ticas do **PMBOK**, garantindo controle de riscos, previsibilidade de custos e aloca√ß√£o eficiente de recursos, aliado a uma execu√ß√£o √°gil, incremental e orientada √† entrega de valor.

---

<br>

# Item 1 - Base de Dados

### Dataset:

Brazilian E-Commerce Dataset by Olist (Kaggle).

---

### Justificativa:

- Dataset real, amplamente utilizado em projetos anal√≠ticos
- Dom√≠nio aderente ao cen√°rio de e-commerce
- Volume superior a 100.000 registros
- Cont√©m dados transacionais e descritivos

---

### Principais tabelas:

- `olist_orders_dataset`
- `olist_order_items_dataset`
- `olist_products_dataset`
- `olist_customers_dataset`
- `olist_geolocation_dataset`

---

<br>

# Item 2 e 3 - Integrar e Explorar (Dadosfera)

### Estrat√©gia de Ingest√£o:

A ingest√£o foi dividida em etapas claras:

### 1Ô∏è‚É£ Extra√ß√£o Kaggle ‚Üí MinIO (Landing)

- Scripts em Python
- Versionamento por `run_id`
- Dados armazenados em formato parquet
- Verifica√ß√£o de Qualidade com Pandera

![Minio](docs/images/minio.png)

---

### 2Ô∏è‚É£ Carga Anal√≠tica no Data Warehouse

- PostgreSQL utilizado como Data Warehouse anal√≠tico
- Transforma√ß√µes realizadas com dbt
- Constru√ß√£o do Star Schema (Kimball) diretamente no DW
- Aplica√ß√£o de testes de qualidade (dbt tests)
- Microtransforma√ß√µes simuladas no contexto anal√≠tico
- Motor de processamento na camada de ingest√£o: DuckDB

![dw](docs/images/dw.png)

---

### 3Ô∏è‚É£ Carga e cataloga√ß√£o dos dados utilizando o m√≥dulo de Coleta da Dadosfera.

- M√≥dulo de Coleta da Dadosfera
- Execu√ß√£o a partir de VPS dedicada
- PostgreSQL em container com SSL habilitado

#### üîó **[[PIPELINE](https://app.dadosfera.ai/pt-BR/collect/pipelines/fb3dc75a-11f8-4c61-99c4-e804871d166d)]**  
#### üîó **[[LINK PARA O DATASET CATALOGADO](https://app.dadosfera.ai/pt-BR/catalog/data-assets?pipeline_id=fb3dc75a-11f8-4c61-99c4-e804871d166d&pipeline_name=RAFAEL%20TRINDADE%20-%20DDF_TECH_122025)]**

![dadosfera](docs/images/dadosfera.png)

---

### 4Ô∏è‚É£ Lakehouse: Landing ‚Üí Bronze / Silver / Gold (Arquitetura B√¥nus)

- Organiza√ß√£o incremental
- Padroniza√ß√£o de schemas
- Prepara√ß√£o para consumo por modelos de ML

---

### üîó Documenta√ß√£o T√©cnica Relacionada
> üìÑ Arquitetura de ingest√£o e processamento: [`data_architecture.md`](docs/data_architecture/README.md)  
> üìÑ Lineage completo dos dados: [`data_lineage.md`](docs/data_lineage/README.md)  
> üìÅ Profiles da camada Landing: [`data_profiling/landing/*`](docs/data_profiling/landing)

---

<br>

# Item 4 - Data Quality

### Abordagem:

A qualidade dos dados foi tratada desde o in√≠cio do pipeline.

---

### Ferramentas Utilizadas:

- **Pandera (Python)** - valida√ß√£o de schemas
- **dbt tests** - testes anal√≠ticos

---

### Entreg√°vel:

> Relat√≥rios de qualidade de dados gerados pela pipeline:  
> üìÅ [`reports/pandera/landing/`](reports/pandera/landing/)  
> üìÅ [`reports/dbt/staging/`](reports/dbt/staging/)  
> üìÅ [`reports/dbt/core/`](reports/dbt/core/)  
> üìÅ [`reports/dbt/marts/`](reports/dbt/marts/)

---

### üîó Documenta√ß√£o T√©cnica Relacionada
> üìÑ Detalhamento das regras de qualidade: [`data_quality.md`](docs/data_quality/README.md)

---

<br>

# Item 5 - GenAI e LLMs

### Objetivo:

Disponibilizar um **cat√°logo de dados t√©cnico e sem√¢ntico** dos Data Marts constru√≠dos, facilitando o entendimento das tabelas anal√≠ticas, m√©tricas, granularidade e regras de neg√≥cio.

---

### Abordagem:

Para a **Prova de Conceito (PoC)**, foi adotada uma abordagem **automatizada e orientada por LLM (Large Language Model)** para gera√ß√£o do cat√°logo de dados, a partir da leitura e interpreta√ß√£o dos modelos SQL dos Data Marts.

O processo consistiu em:

- Leitura automatizada dos arquivos `.sql` dos modelos anal√≠ticos (dbt marts)
- Defini√ß√£o de um template sem√¢ntico de documenta√ß√£o como refer√™ncia
- Aplica√ß√£o controlada de **engenharia de prompt (Few-Shot)**, utilizando exemplos pr√©vios de Data Marts documentados para orientar o modelo
- Envio do conte√∫do dos modelos SQL para um **LLM**, respons√°vel por:
  - Interpretar o prop√≥sito da tabela
  - Identificar m√©tricas, dimens√µes e granularidade
  - Gerar descri√ß√µes t√©cnicas e sem√¢nticas em linguagem natural
- Gera√ß√£o autom√°tica de documenta√ß√£o em formato **Markdown**
- Versionamento do cat√°logo junto ao c√≥digo-fonte do projeto

---

### Benef√≠cios da Abordagem com LLM:

- Redu√ß√£o de esfor√ßo manual na documenta√ß√£o
- Padroniza√ß√£o das descri√ß√µes dos Data Marts
- Facilidade de manuten√ß√£o e atualiza√ß√£o do cat√°logo
- Demonstra√ß√£o pr√°tica do uso de **IA aplicada √† governan√ßa de dados**
- Ader√™ncia ao contexto de PoC, priorizando agilidade e entrega de valor

---

### Entreg√°vel:

> Cat√°logo de dados gerado automaticamente a partir dos modelos SQL:  
> üìÅ [`data_catalog/*`](docs/data_catalog/)

---

<br>

# Item 6 - Modelagem de Dados

Modelagem dimensional seguindo os princ√≠pios de Ralph Kimball.

### Esquema:
 
 Star Schema (Tabelas Fato e Dimens√£o).

---

### Justificativa:

Otimiza√ß√£o para consultas anal√≠ticas e performance no BI.

---

### Estrutura Final:

**Fato:**

- `fact_order_items`

**Dimens√µes:**

- `dim_customers`
- `dim_products`
- `dim_geolocation`
- `dim_date` *(dbt_seed)*
- `dim_time` *(dbt_seed)*

---

### `modelo_olap`

![Modelagem](docs/images/olap.png)

---

### origem: `modelo_oltp`

![oltp](docs/images/oltp.png)

---

### üîó Documenta√ß√£o T√©cnica Relacionada
> üìÑ Rastreabilidade das transforma√ß√µes: [`data_lineage.md`](docs/data_lineage/README.md)  
> üìÅ Cat√°logo sem√¢ntico dos Data Marts: [`data_catalog/*`](docs/data_catalog/)

---

<br>

# Item 7 - Analisar (Visualiza√ß√£o)

### Acesso ao m√≥dulo de Visualiza√ß√£o:

Foi utilizado o m√≥dulo **Visualiza√ß√£o** da Dadosfera, acessado com as **mesmas credenciais do ambiente**, onde os datasets s√£o identificados por meio de um **ID t√©cnico da tabela**.

Exemplo de identifica√ß√£o do dataset na Dadosfera:
- **Database:** `DADOSFERA_PRD_TREINAMENTOS`
- **Schema:** `PUBLIC`
- **Tabela (ID):** `TB__9C6HQS__DW_MARTS__MART_*`

---

### Organiza√ß√£o:

Foi criada uma **Cole√ß√£o** no Metabase seguindo o padr√£o solicitado:

```text
Rafael Trindade - 122025
```

Dentro dessa cole√ß√£o foram salvas todas as **queries SQL** e **visualiza√ß√µes** desenvolvidas neste item.

---

### Visualiza√ß√µes Criadas:
Foram criadas **5 perguntas (queries)** utilizando **5 tipos diferentes de visualiza√ß√£o**, conforme solicitado:

1. **Top 15 Categorias por Receita**  
   Tipo: Gr√°fico de Barras  
   An√°lise do mix de produtos e concentra√ß√£o de receita.

2. **Receita Mensal ao Longo do Tempo**  
   Tipo: Gr√°fico de Linha  
   An√°lise de tend√™ncia e sazonalidade mensal.

3. **Receita Di√°ria ao Longo do Tempo**  
   Tipo: Gr√°fico de Linha (s√©rie temporal di√°ria)  
   Identifica√ß√£o de picos, quedas e varia√ß√µes di√°rias.

4. **Receita por Dia da Semana**  
   Tipo: Gr√°fico de Barras  
   An√°lise de padr√µes de consumo ao longo da semana.

5. **Crescimento Mensal (%) por Categoria de Produto**  
   Tipo: Tabela Anal√≠tica com Formata√ß√£o Condicional (Heatmap Anal√≠tico)  
   An√°lise da din√¢mica de crescimento percentual por categoria ao longo do tempo, utilizando cores divergentes para facilitar a compara√ß√£o visual entre per√≠odos e categorias.

Cada visualiza√ß√£o teve sua **query SQL salva** e o **print do resultado** anexado a este documento como evid√™ncia da execu√ß√£o.

---

### üìä Visualiza√ß√µes e An√°lises Criadas:

A seguir est√£o as visualiza√ß√µes desenvolvidas no m√≥dulo de **Visualiza√ß√£o da Dadosfera**, com foco em an√°lise de categorias e s√©ries temporais, utilizando os dados do Data Mart.

### 1Ô∏è‚É£ Top 15 Categorias por Receita Total

**Pergunta:**  
Quais s√£o as categorias de produtos que mais geram receita no per√≠odo analisado?

**Descri√ß√£o:**  
Esta visualiza√ß√£o identifica as categorias com maior contribui√ß√£o de receita total, permitindo compreender onde est√° concentrado o faturamento do neg√≥cio.

**Query SQL**
```sql
SELECT
    PRODUCT_CATEGORY_NAME,
    SUM(RECEITA_CATEGORIA) AS RECEITA_CATEGORIA
FROM "DADOSFERA_PRD_TREINAMENTOS"."PUBLIC"."TB__9C6HQS__DW_MARTS__MART_PRODUCT_CATEGORY_PERFORMANCE"
GROUP BY PRODUCT_CATEGORY_NAME
ORDER BY RECEITA_CATEGORIA DESC
LIMIT 15;
```
![Top 15 Categorias por Receita](docs/images/top_categorias_receita.png)

---

### 2Ô∏è‚É£ Receita Mensal ao Longo do Tempo

**Pergunta:**  
Como a receita evolui m√™s a m√™s ao longo do tempo?

**Descri√ß√£o:**  
An√°lise de s√©rie temporal que mostra o comportamento da receita mensal, possibilitando identificar tend√™ncias, sazonalidades e padr√µes de crescimento.

**Query SQL**
```sql
SELECT
    TO_DATE(ANO || '-' || LPAD(MES, 2, '0') || '-01') AS PERIODO,
    SUM(RECEITA_MENSAL) AS RECEITA_MENSAL
FROM "DADOSFERA_PRD_TREINAMENTOS"."PUBLIC"."TB__9C6HQS__DW_MARTS__MART_SALES_MONTHLY"
GROUP BY PERIODO
ORDER BY PERIODO;
```
![Receita Mensal](docs/images/receita_mensal.png)

---

### 3Ô∏è‚É£ Receita Di√°ria

**Pergunta:**  
Como a receita se comporta diariamente ao longo do per√≠odo analisado?

**Descri√ß√£o:**  
Visualiza√ß√£o que detalha a varia√ß√£o di√°ria da receita, √∫til para identificar picos, quedas pontuais e padr√µes operacionais no curto prazo.

**Query SQL**
```sql
SELECT
    DATA,
    RECEITA_DIARIA
FROM "DADOSFERA_PRD_TREINAMENTOS"."PUBLIC"."TB__9C6HQS__DW_MARTS__MART_SALES_DAILY"
ORDER BY DATA;
```
![Receita Di√°ria](docs/images/receita_diaria.png)

---

### 4Ô∏è‚É£ Receita por Dia da Semana

**Pergunta:**  
Quais dias da semana concentram maior volume de receita?

**Descri√ß√£o:**  
An√°lise agregada por dia da semana, permitindo identificar comportamentos de consumo recorrentes e apoiar decis√µes operacionais e comerciais.

**Query SQL**
```sql
SELECT
    NOME_DIA_SEMANA,
    RECEITA_TOTAL,
    CASE NOME_DIA_SEMANA
        WHEN 'Segunda-feira' THEN 1
        WHEN 'Ter√ßa-feira'   THEN 2
        WHEN 'Quarta-feira'  THEN 3
        WHEN 'Quinta-feira'  THEN 4
        WHEN 'Sexta-feira'   THEN 5
        WHEN 'S√°bado'        THEN 6
        WHEN 'Domingo'       THEN 7
    END AS ORDEM_DIA
FROM "DADOSFERA_PRD_TREINAMENTOS"."PUBLIC"."TB__9C6HQS__DW_MARTS__MART_SALES_WEEKDA"
ORDER BY ORDEM_DIA;

```
![Receita por Dia da Semana](docs/images/receita_dia_semana.png)

---

### 5Ô∏è‚É£ Crescimento Percentual Mensal por Categoria

**Pergunta:**  
Quais categorias apresentam crescimento de percentual ao longo do tempo?

**Descri√ß√£o:**  
Tabela anal√≠tica com formata√ß√£o condicional que representa visualmente o crescimento percentual mensal das categorias ao longo do tempo, permitindo r√°pida identifica√ß√£o de varia√ß√µes positivas e negativas entre per√≠odos e categorias.

**Query SQL**
```sql
SELECT
    PRODUCT_CATEGORY_NAME,
    ANO,
    MES,
    CRESCIMENTO_PERCENTUAL
FROM "DADOSFERA_PRD_TREINAMENTOS"."PUBLIC"."TB__9C6HQS__DW_MARTS__MART_CATEGORY_GROWTH_MONTHLY"
WHERE CRESCIMENTO_PERCENTUAL IS NOT NULL
ORDER BY PRODUCT_CATEGORY_NAME, ANO, MES;
```
![Crescimento Mensal por Categoria](docs/images/crescimento_categoria.png)

---

### üîó Documenta√ß√£o T√©cnica Relacionada
> üìÑ Arquitetura de ingest√£o e processamento: [`data_architecture.md`](docs/data_architecture/README.md)  
> üìÑ Lineage completo dos dados: [`data_lineage.md`](docs/data_lineage/README.md)  
> üìÅ Defini√ß√£o das m√©tricas e tabelas anal√≠ticas: [`data_catalog/*`](docs/data_catalog/)

---

### üîó Acesso ao Dashboard:

O dashboard consolidando todas as visualiza√ß√µes criadas neste item est√° dispon√≠vel no m√≥dulo de Visualiza√ß√£o da Dadosfera e pode ser acessado por meio do link abaixo:

#### üîó **[[DASHBOARD METABASE DADOSFERA](https://metabase-treinamentos.dadosfera.ai/dashboard/229-rafael-trindade-122025-dashboard)]**


![Metabase](docs/images/metabase.png)

---

<br>

# Item 8 - Pipelines

### Considera√ß√µes T√©cnicas:

Para viabilizar a integra√ß√£o segura entre a infraestrutura de dados e a plataforma da Dadosfera, foi necess√°ria a configura√ß√£o de um **banco PostgreSQL em container Docker com SSL/TLS habilitado**, executando em uma **VPS dedicada**.

Essa configura√ß√£o garantiu:
- Comunica√ß√£o criptografada entre a Dadosfera e o banco de dados
- Seguran√ßa no processo de ingest√£o e processamento dos dados
- Estabilidade e confiabilidade para execu√ß√£o dos pipelines

---

### üîó Documenta√ß√£o T√©cnica Relacionada
> üìÑ Arquitetura e organiza√ß√£o dos pipelines: [`data_architecture.md`](docs/data_architecture/README.md)  
> üìÑ Estrat√©gia de governan√ßa, versionamento e reprocessamento: [`data_governance.md`](docs/data_governance/README.md)  
> üìÑ Infraestrutura - PostgreSQL com SSL/TLS em Docker: [`postgres_ssl_setup.md`](docs/infrastructure/postgres_ssl_setup.md)

---

#### üîó **[[PIPELINE DADOSFERA](https://app.dadosfera.ai/pt-BR/collect/pipelines/fb3dc75a-11f8-4c61-99c4-e804871d166d)]**

![dadosfera](docs/images/dadosfera.png)

---

<br>

# Item 9 - Data App (Streamlit)

Desenvolvimento de um Data App interativo com Streamlit, implantado em uma VPS dedicada.

O aplicativo disponibiliza visualiza√ß√µes anal√≠ticas das marts constru√≠das, permitindo o acompanhamento centralizado de indicadores de neg√≥cio.

A aplica√ß√£o foi configurada para execu√ß√£o cont√≠nua no servidor, com acesso p√∫blico via navegador.

---

#### üîó **[[STREAMLIT VPS](http://54.39.98.107:8501/)]**

![Streamlit](docs/images/streamlit.png)

---

<br>

# Item 10 - Apresenta√ß√£o (Pitch T√©cnico)

Apresenta√ß√£o da solu√ß√£o desenvolvida e demonstra√ß√£o da viabilidade de substitui√ß√£o de uma arquitetura anal√≠tica manual pela plataforma Dadosfera.

O pitch aborda:
- O que foi validado na Prova de Conceito
- As limita√ß√µes operacionais de uma arquitetura gerenciada manualmente
- Como a Dadosfera centraliza, governa e escala o ciclo de dados
- Pr√≥ximos passos estrat√©gicos ap√≥s a PoC

#### üîó **[[APRESENTA√á√ÉO DO CASE T√âCNICO](https://youtu.be/Qdtoash-hRI)]**

---

### üîó Documenta√ß√£o Complementar
> üìÑ Narrativa executiva do case e pitch t√©cnico: [`presentation.md`](docs/presentation/README.md)

---
<br>

## üèÅ Conclus√£o - Por que a Dadosfera?

A **Prova de Conceito (PoC)** demonstrou que √© plenamente poss√≠vel construir, com ferramentas open source, uma arquitetura anal√≠tica robusta, bem governada e orientada a neg√≥cio. Os dados da Olist foram estruturados desde a ingest√£o at√© o consumo, com qualidade, rastreabilidade, modelagem dimensional e visualiza√ß√µes anal√≠ticas funcionais.

No entanto, essa PoC tamb√©m evidencia um ponto cr√≠tico: **manter essa arquitetura manualmente exige alto esfor√ßo operacional**. √â necess√°rio gerenciar servidores, garantir disponibilidade, monitorar pipelines, versionar documenta√ß√£o, manter cat√°logos atualizados, controlar acessos e assegurar que a governan√ßa n√£o se degrade com o tempo. √Ä medida que o volume de dados, o n√∫mero de usu√°rios e a complexidade anal√≠tica crescem, esse modelo se torna caro, fr√°gil e pouco escal√°vel.

√â nesse contexto que a **Dadosfera se posiciona como a evolu√ß√£o natural da solu√ß√£o**.

A plataforma consolida, em um √∫nico ambiente:
- **Centraliza√ß√£o do ciclo de dados**, eliminando a fragmenta√ß√£o entre ingest√£o, cat√°logo, governan√ßa e consumo  
- **Cat√°logo de dados vivo e autom√°tico**, com linhagem, metadados e contexto de neg√≥cio sempre atualizados  
- **Governan√ßa aplicada por padr√£o**, reduzindo depend√™ncia de controles manuais e documenta√ß√£o paralela  
- **Escalabilidade e confiabilidade**, sem a necessidade de gest√£o direta de infraestrutura  
- **Democratiza√ß√£o do acesso aos dados**, permitindo que analistas e √°reas de neg√≥cio consumam informa√ß√£o com autonomia e seguran√ßa  

A PoC prova que a estrat√©gia de dados √© tecnicamente vi√°vel.  
A **Dadosfera prova que essa estrat√©gia pode escalar de forma sustent√°vel, segura e econ√¥mica**.

Em vez de investir tempo e recursos na manuten√ß√£o de uma arquitetura distribu√≠da e complexa, a organiza√ß√£o passa a focar no que realmente gera valor: **an√°lise, decis√£o e inova√ß√£o orientadas por dados**.

Dessa forma, a Dadosfera n√£o substitui apenas ferramentas.  
Ela **substitui complexidade operacional por intelig√™ncia de neg√≥cio**, transformando uma PoC bem-sucedida em uma **plataforma anal√≠tica pronta para produ√ß√£o**.

